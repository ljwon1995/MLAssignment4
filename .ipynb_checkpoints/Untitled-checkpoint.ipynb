{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time    \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = './horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the values of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1027, shuffle=False, num_workers=1)  \n",
    "\n",
    "validation_data_path = './horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=256, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "trainList = list()\n",
    "validList = list()\n",
    "trainLabelList = list()\n",
    "validLabelList = list()\n",
    "\n",
    "for i, data in enumerate(trainloader):\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "\n",
    "\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "\n",
    "    batch_size = inputs.shape[0]\n",
    "\n",
    "    # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "    # change inputs to matrix 10000*batch_size\n",
    "    for bat_idx in range(batch_size):\n",
    "\n",
    "        targMat = inputs[bat_idx][0]\n",
    "\n",
    "        colVec = np.reshape(targMat, (np.product(targMat.shape), 1), 'F')\n",
    "\n",
    "        if(bat_idx == 0):\n",
    "            batMat = colVec\n",
    "        else:\n",
    "            batMat = np.concatenate((batMat, colVec), axis = 1)         \n",
    "\n",
    "    # Add ones because of the value b in coefficient\n",
    "    ones = np.ones((1, batch_size), dtype = int)\n",
    "    batMat = np.concatenate((batMat, ones))\n",
    "    trainList.append(batMat)\n",
    "    trainLabelList.append(labels)\n",
    "    \n",
    "# load validation images of the batch size for every iteration\n",
    "for i, data in enumerate(valloader):\n",
    "\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "     # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "\n",
    "    batch_size = inputs.shape[0]\n",
    "\n",
    "    # Change Inputs to matrix 10000*batch_size\n",
    "\n",
    "    for bat_idx in range(batch_size):\n",
    "        targMat = inputs[bat_idx][0]\n",
    "        colVec = np.reshape(targMat, (np.product(targMat.shape), 1), 'F')\n",
    "\n",
    "        if(bat_idx == 0):\n",
    "            batMat = colVec\n",
    "        else:\n",
    "            batMat = np.concatenate((batMat,colVec), axis = 1)\n",
    "        \n",
    "    # Add ones because of the value b in coefficient\n",
    "    ones = np.ones((1, batch_size), dtype = int)\n",
    "    batMat = np.concatenate((batMat, ones))\n",
    "    validList.append(batMat)\n",
    "    validLabelList.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Coefs\n",
    "'''\n",
    "w_0 = np.zeros((1,10001), dtype = float)\n",
    "a = np.ones((1,10001), dtype = float)\n",
    "w_0 =np.concatenate((w_0, a), axis = 0)\n",
    "a = 2 * np.ones((1,10001), dtype = float)\n",
    "w_0 =np.concatenate((w_0, a), axis = 0)\n",
    "a = 3 * np.ones((1,10001), dtype = float)\n",
    "w_0 =np.concatenate((w_0, a), axis = 0)\n",
    "\n",
    "\n",
    "w_1 = np.array([[0,0,0,0],\n",
    "              [1,1,1,1],\n",
    "              [2,2,2,2]], dtype = float)\n",
    "\n",
    "w_2 = np.zeros((1, 3), dtype = float)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "w_0 = np.random.random((4,10001))\n",
    "w_1 = np.random.random((3,4))\n",
    "w_2 = np.random.random((1,3))\n",
    "\n",
    "\n",
    "#set DataNum\n",
    "totalDataNum = len(trainloader.dataset)\n",
    "\n",
    "#Set Learning Rate\n",
    "lrnRate = 0.01\n",
    "\n",
    "# Set Loss Lists\n",
    "lrnLoss = list()\n",
    "valLoss = list()\n",
    "\n",
    "# Set Accurate Lists\n",
    "lrnAcc = list()\n",
    "valAcc = list()\n",
    "\n",
    "# set Elapsed time Lists\n",
    "elapTime = list()\n",
    "\n",
    "\n",
    "epoch = -1\n",
    "lrnAccRate = 0\n",
    "\n",
    "while(lrnAccRate < 1 ):\n",
    "#while(epoch < 10000):\n",
    "    epoch += 1\n",
    "\n",
    "\n",
    "    \n",
    "    #Set Sum of Loss to 0\n",
    "    sumL = 0\n",
    "    \n",
    "    #Set Sum of Cor to 0\n",
    "    cor = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    for i, a_0 in enumerate(trainList):\n",
    "        \n",
    "        batch_size = a_0.shape[1]\n",
    "\n",
    "        # Start Regression Calculation\n",
    "        z_0 = np.dot(w_0, a_0)          \n",
    "\n",
    "        a_1 = 1/(1 + np.exp(-z_0))                                               \n",
    "        z_1 = np.dot(w_1, a_1)\n",
    "        a_2 = 1/(1 + np.exp(-z_1))\n",
    "        \n",
    "        z_2 = np.dot(w_2, a_2)\n",
    "        a_3 = 1/(1 + np.exp(-z_2))\n",
    "   \n",
    "    \n",
    "        dz_2 = np.subtract(a_3, trainLabelList[i])  \n",
    "\n",
    "        dw_2 = np.dot(dz_2, a_2.T) / totalDataNum\n",
    "        w_2 -= lrnRate * dw_2\n",
    "        \n",
    "        da_2 = np.dot(w_2.T, dz_2)\n",
    "        dz_1 = da_2 * a_2 * (1 - a_2) \n",
    "        dw_1 = np.dot(dz_1, a_1.T) / totalDataNum\n",
    "        w_1 -= lrnRate * dw_1\n",
    "        \n",
    "        da_1 = np.dot(w_1.T, dz_1)\n",
    "        dz_0 = da_1 * a_1 * (1 - a_1)\n",
    "        dw_0 = np.dot(dz_0, a_0.T) / totalDataNum\n",
    "        w_0 -= lrnRate * dw_0\n",
    "\n",
    "        \n",
    "        # Calculate Total Loss\n",
    "        a_3 = torch.from_numpy(a_3)                                             #change ndarray to tensor\n",
    "        dLabels = trainLabelList[i].double()                                   #change tensor type to double\n",
    "        L = -(dLabels) * np.log(a_3) - (1-dLabels) * np.log(1-a_3)      \n",
    "        sumL += L.sum()\n",
    "        \n",
    "        \n",
    "        # Calculate Accuracy\n",
    "\n",
    "\n",
    "        for batIdx in range(batch_size):\n",
    "\n",
    "            if(a_3[0][batIdx] <= 0.5 and trainLabelList[i][batIdx] == 0):\n",
    "                cor += 1\n",
    "\n",
    "            if(a_3[0][batIdx] > 0.5 and trainLabelList[i][batIdx] == 1):\n",
    "                cor += 1\n",
    "            \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    elapTime.append(elapsed_time)\n",
    "    \n",
    "\n",
    "    # Calculate TotalLoss\n",
    "    sumL /= totalDataNum\n",
    "\n",
    "    lrnLoss.append(sumL)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    \n",
    "    lrnAccRate = cor/totalDataNum\n",
    "    lrnAcc.append(lrnAccRate)\n",
    "    \n",
    "                \n",
    "\n",
    "\n",
    "    # Set Sum Of Valid Loss to 0\n",
    "    sumVL = 0\n",
    "    # Set Sum of Valid Cor to 0\n",
    "    vCor = 0\n",
    "    \n",
    "    # load validation images of the batch size for every iteration\n",
    "    for i, a_0 in enumerate(validList):\n",
    "        \n",
    "        \n",
    "        batch_size = a_0.shape[1]\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # Start Calculate Loss \n",
    "        z_0 = np.dot(w_0, a_0)\n",
    "        a_1= 1/(1+np.exp(-z_0))\n",
    "        \n",
    "        z_1 = np.dot(w_1, a_1)\n",
    "        a_2= 1/(1+np.exp(-z_1))\n",
    "        \n",
    "        z_2 = np.dot(w_2, a_2)\n",
    "        a_3= 1/(1+np.exp(-z_2))\n",
    "        \n",
    "        \n",
    "        a_3 = torch.from_numpy(a_3)\n",
    "        dLabels = validLabelList[i].double()\n",
    "        L = -(dLabels) * np.log(a_3) - (1-dLabels) * np.log(1-a_3)\n",
    "        sumVL += L.sum()\n",
    "        \n",
    "\n",
    "        \n",
    "        # Calculate Accuracy\n",
    "        \n",
    "        for batIdx in range(batch_size):\n",
    "            if(a_3[0][batIdx] <= 0.5 and validLabelList[i][batIdx] == 0):\n",
    "                vCor += 1\n",
    "                \n",
    "            if(a_3[0][batIdx] > 0.5 and validLabelList[i][batIdx] == 1):\n",
    "                vCor += 1\n",
    "    \n",
    "    totalValDataNum = len(valloader.dataset)\n",
    "    \n",
    "    # CalCulate Total Loss\n",
    "    sumVL /= totalValDataNum\n",
    "    valLoss.append(sumVL)\n",
    "    \n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    vAcc = vCor/totalValDataNum\n",
    "    valAcc.append(vAcc)\n",
    "\n",
    "    \n",
    "\n",
    "    if epoch%1000 == 0:\n",
    "        print(\"-------------- epoch %6d\" % epoch, \"--------------\")\n",
    "        print(\"lrnCor : \", cor)\n",
    "        print(\"valCor : \", vCor) \n",
    "        print(\"total loss : \", sumL.item())\n",
    "        print(\"total valid loss : \", sumVL.item())\n",
    "        print(\"-------------------------------------------\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Loss\n",
    "\n",
    "fig, axs = plt.subplots(2,1, figsize = (10,4))\n",
    "\n",
    "\n",
    "axs[0].plot(lrnLoss, color = 'red', label = \"TrainingLoss\")\n",
    "\n",
    "\n",
    "axs[1].plot(valLoss, color = 'blue', label = \"ValidationLoss\")\n",
    "\n",
    "axs[0].set(ylabel = 'Loss')\n",
    "axs[1].set(xlabel = 'Iteration', ylabel = 'Loss')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Accuracy\n",
    "fig, axs = plt.subplots(2,1, figsize = (10,5))\n",
    "\n",
    "\n",
    "axs[0].plot(lrnAcc, color = 'orange', label = \"TrainingAccuracy\")\n",
    "\n",
    "\n",
    "axs[1].plot(valAcc, color = 'green', label = \"ValidationAccuracy\")\n",
    "\n",
    "axs[0].set(ylabel = 'Accuracy')\n",
    "axs[1].set(xlabel = 'Iteration', ylabel = 'Accuracy')\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Altogether\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.title('Altogether')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.plot(lrnLoss, color = 'red', label = 'TrainingLoss')\n",
    "plt.plot(valLoss, color = 'blue', label = \"ValidationLoss\")\n",
    "plt.plot(lrnAcc, color = 'orange', label = \"TrainingAccuracy\")\n",
    "plt.plot(valAcc, color = 'green', label = \"ValidationAccuracy\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  Dataset   |   Loss | Accuracy\")\n",
    "print(\"  Training  | %.4f | %.4f\" % (lrnLoss[-1], lrnAcc[-1]))\n",
    "print(\" Validation | %.4f | %.4f\" % (valLoss[-1], valAcc[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
